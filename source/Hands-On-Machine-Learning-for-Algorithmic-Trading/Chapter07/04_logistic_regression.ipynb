{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use logistic regression for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lasso L1 penalty and the ridge L2 penalty can both be used with logistic regression. They have the same shrinkage effect as we have just discussed, and the lasso can again be used for variable selection with any linear regression model.\n",
    "\n",
    "Just as with linear regression, it is important to standardize the input variables as the regularized models are scale sensitive. The regularization hyperparameter also requires tuning using cross-validation as in the linear regression case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to predict price movements using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue the price prediction example but now we binarize the outcome variable so that it takes on the value 1 whenever the 10-day return is positive and 0 otherwise; see the notebook logistic_regression.ipynb in the sub directory stock_price_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import talib\n",
    "import re\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline import Pipeline, factors, filters, classifiers\n",
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "from quantopian.pipeline.factors import (Latest, \n",
    "                                         Returns, \n",
    "                                         AverageDollarVolume, \n",
    "                                         SimpleMovingAverage,\n",
    "                                         EWMA,\n",
    "                                         BollingerBands,\n",
    "                                         CustomFactor,\n",
    "                                         MarketCap,\n",
    "                                        SimpleBeta)\n",
    "from quantopian.pipeline.filters import QTradableStocksUS, StaticAssets\n",
    "from quantopian.pipeline.data.quandl import fred_usdontd156n as libor\n",
    "from empyrical import max_drawdown, sortino_ratio\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Fundamentals #\n",
    "################\n",
    "\n",
    "# Morningstar fundamentals (2002 - Ongoing)\n",
    "# https://www.quantopian.com/help/fundamentals\n",
    "from quantopian.pipeline.data import Fundamentals\n",
    "\n",
    "#####################\n",
    "# Analyst Estimates #\n",
    "#####################\n",
    "\n",
    "# Earnings Surprises - Zacks (27 May 2006 - Ongoing)\n",
    "# https://www.quantopian.com/data/zacks/earnings_surprises\n",
    "from quantopian.pipeline.data.zacks import EarningsSurprises\n",
    "from quantopian.pipeline.factors.zacks import BusinessDaysSinceEarningsSurprisesAnnouncement\n",
    "\n",
    "##########\n",
    "# Events #\n",
    "##########\n",
    "\n",
    "# Buyback Announcements - EventVestor (01 Jun 2007 - Ongoing)\n",
    "# https://www.quantopian.com/data/eventvestor/buyback_auth\n",
    "from quantopian.pipeline.data.eventvestor import BuybackAuthorizations\n",
    "from quantopian.pipeline.factors.eventvestor import BusinessDaysSinceBuybackAuth\n",
    "\n",
    "# CEO Changes - EventVestor (01 Jan 2007 - Ongoing)\n",
    "# https://www.quantopian.com/data/eventvestor/ceo_change\n",
    "from quantopian.pipeline.data.eventvestor import CEOChangeAnnouncements\n",
    "\n",
    "# Dividends - EventVestor (01 Jan 2007 - Ongoing)\n",
    "# https://www.quantopian.com/data/eventvestor/dividends\n",
    "from quantopian.pipeline.data.eventvestor import (\n",
    "    DividendsByExDate,\n",
    "    DividendsByPayDate,\n",
    "    DividendsByAnnouncementDate,\n",
    ")\n",
    "from quantopian.pipeline.factors.eventvestor import (\n",
    "    BusinessDaysSincePreviousExDate,\n",
    "    BusinessDaysUntilNextExDate,\n",
    "    BusinessDaysSinceDividendAnnouncement,\n",
    ")\n",
    "\n",
    "# Earnings Calendar - EventVestor (01 Jan 2007 - Ongoing)\n",
    "# https://www.quantopian.com/data/eventvestor/earnings_calendar\n",
    "from quantopian.pipeline.data.eventvestor import EarningsCalendar\n",
    "from quantopian.pipeline.factors.eventvestor import (\n",
    "    BusinessDaysUntilNextEarnings,\n",
    "    BusinessDaysSincePreviousEarnings\n",
    ")\n",
    "\n",
    "# 13D Filings - EventVestor (01 Jan 2007 - Ongoing)\n",
    "# https://www.quantopian.com/data/eventvestor/_13d_filings\n",
    "from quantopian.pipeline.data.eventvestor import _13DFilings\n",
    "from quantopian.pipeline.factors.eventvestor import BusinessDaysSince13DFilingsDate\n",
    "\n",
    "#############\n",
    "# Sentiment #\n",
    "#############\n",
    "\n",
    "# News Sentiment - Sentdex Sentiment Analysis (15 Oct 2012 - Ongoing)\n",
    "# https://www.quantopian.com/data/sentdex/sentiment\n",
    "from quantopian.pipeline.data.sentdex import sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trading days per period\n",
    "MONTH = 21\n",
    "YEAR = 12 * MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '2014-01-01'\n",
    "END = '2015-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q100US():\n",
    "    return filters.make_us_equity_universe(\n",
    "        target_size=100,\n",
    "        rankby=factors.AverageDollarVolume(window_length=200),\n",
    "        mask=filters.default_us_equity_universe_mask(),\n",
    "        groupby=classifiers.fundamentals.Sector(),\n",
    "        max_group_weight=0.3,\n",
    "        smoothing_func=lambda f: f.downsample('month_start'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIVERSE = StaticAssets(symbols(['MSFT', 'AAPL']))\n",
    "UNIVERSE = Q100US()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnualizedData(CustomFactor):\n",
    "    # Get the sum of the last 4 reported values\n",
    "    window_length = 260\n",
    "\n",
    "    def compute(self, today, assets, out, asof_date, values):\n",
    "        for asset in range(len(assets)):\n",
    "            # unique asof dates indicate availability of new figures\n",
    "            _, filing_dates = np.unique(asof_date[:, asset], return_index=True)\n",
    "            quarterly_values = values[filing_dates[-4:], asset]\n",
    "            # ignore annual windows with <4 quarterly data points\n",
    "            if len(~np.isnan(quarterly_values)) != 4:\n",
    "                out[asset] = np.nan\n",
    "            else:\n",
    "                out[asset] = np.sum(quarterly_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnualAvg(CustomFactor):\n",
    "    window_length = 252\n",
    "    \n",
    "    def compute(self, today, assets, out, values):\n",
    "        out[:] = (values[0] + values[-1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_pipeline(factors):\n",
    "    start = time()\n",
    "    pipe = Pipeline({k: v(mask=UNIVERSE).rank() for k, v in factors.items()},\n",
    "                    screen=UNIVERSE)\n",
    "    result = run_pipeline(pipe, start_date=START, end_date=END)\n",
    "    return result, time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueFactors:\n",
    "    \"\"\"Definitions of factors for cross-sectional trading algorithms\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def PriceToSalesTTM(**kwargs):\n",
    "        \"\"\"Last closing price divided by sales per share\"\"\"        \n",
    "        return Fundamentals.ps_ratio.latest\n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToEarningsTTM(**kwargs):\n",
    "        \"\"\"Closing price divided by earnings per share (EPS)\"\"\"\n",
    "        return Fundamentals.pe_ratio.latest\n",
    " \n",
    "    @staticmethod\n",
    "    def PriceToDilutedEarningsTTM(mask):\n",
    "        \"\"\"Closing price divided by diluted EPS\"\"\"\n",
    "        last_close = USEquityPricing.close.latest\n",
    "        diluted_eps = AnnualizedData(inputs = [Fundamentals.diluted_eps_earnings_reports_asof_date,\n",
    "                                               Fundamentals.diluted_eps_earnings_reports],\n",
    "                                     mask=mask)\n",
    "        return last_close / diluted_eps\n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToForwardEarnings(**kwargs):\n",
    "        \"\"\"Price to Forward Earnings\"\"\"\n",
    "        return Fundamentals.forward_pe_ratio.latest\n",
    "    \n",
    "    @staticmethod\n",
    "    def DividendYield(**kwargs):\n",
    "        \"\"\"Dividends per share divided by closing price\"\"\"\n",
    "        return Fundamentals.trailing_dividend_yield.latest\n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToFCF(mask):\n",
    "        \"\"\"Price to Free Cash Flow\"\"\"\n",
    "        last_close = USEquityPricing.close.latest\n",
    "        fcf_share = AnnualizedData(inputs = [Fundamentals.fcf_per_share_asof_date,\n",
    "                                             Fundamentals.fcf_per_share],\n",
    "                                   mask=mask)\n",
    "        return last_close / fcf_share\n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToOperatingCashflow(mask):\n",
    "        \"\"\"Last Close divided by Operating Cash Flows\"\"\"\n",
    "        last_close = USEquityPricing.close.latest\n",
    "        cfo_per_share = AnnualizedData(inputs = [Fundamentals.cfo_per_share_asof_date,\n",
    "                                                 Fundamentals.cfo_per_share],\n",
    "                                       mask=mask)        \n",
    "        return last_close / cfo_per_share\n",
    "\n",
    "    @staticmethod\n",
    "    def PriceToBook(mask):\n",
    "        \"\"\"Closing price divided by book value\"\"\"\n",
    "        last_close = USEquityPricing.close.latest\n",
    "        book_value_per_share = AnnualizedData(inputs = [Fundamentals.book_value_per_share_asof_date,\n",
    "                                              Fundamentals.book_value_per_share],\n",
    "                                             mask=mask)        \n",
    "        return last_close / book_value_per_share\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def EVToFCF(mask):\n",
    "        \"\"\"Enterprise Value divided by Free Cash Flows\"\"\"\n",
    "        fcf = AnnualizedData(inputs = [Fundamentals.free_cash_flow_asof_date,\n",
    "                                       Fundamentals.free_cash_flow],\n",
    "                             mask=mask)\n",
    "        return Fundamentals.enterprise_value.latest / fcf\n",
    "\n",
    "    @staticmethod\n",
    "    def EVToEBITDA(mask):\n",
    "        \"\"\"Enterprise Value to Earnings Before Interest, Taxes, Deprecation and Amortization (EBITDA)\"\"\"\n",
    "        ebitda = AnnualizedData(inputs = [Fundamentals.ebitda_asof_date,\n",
    "                                          Fundamentals.ebitda],\n",
    "                                mask=mask)\n",
    "\n",
    "        return Fundamentals.enterprise_value.latest / ebitda\n",
    "\n",
    "    @staticmethod\n",
    "    def EBITDAYield(mask):\n",
    "        \"\"\"EBITDA divided by latest close\"\"\"\n",
    "        ebitda = AnnualizedData(inputs = [Fundamentals.ebitda_asof_date,\n",
    "                                          Fundamentals.ebitda],\n",
    "                                mask=mask)\n",
    "        return USEquityPricing.close.latest / ebitda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_FACTORS = {\n",
    "    'DividendYield'            : ValueFactors.DividendYield,\n",
    "    'EBITDAYield'              : ValueFactors.EBITDAYield,\n",
    "    'EVToEBITDA'               : ValueFactors.EVToEBITDA,\n",
    "    'EVToFCF'                  : ValueFactors.EVToFCF,\n",
    "    'PriceToBook'              : ValueFactors.PriceToBook,\n",
    "    'PriceToDilutedEarningsTTM': ValueFactors.PriceToDilutedEarningsTTM,\n",
    "    'PriceToEarningsTTM'       : ValueFactors.PriceToEarningsTTM,\n",
    "    'PriceToFCF'               : ValueFactors.PriceToFCF,\n",
    "    'PriceToForwardEarnings'   : ValueFactors.PriceToForwardEarnings,\n",
    "    'PriceToOperatingCashflow' : ValueFactors.PriceToOperatingCashflow,\n",
    "    'PriceToSalesTTM'          : ValueFactors.PriceToSalesTTM,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_result, t = factor_pipeline(VALUE_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "value_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MomentumFactors:\n",
    "    \"\"\"Custom Momentum Factors\"\"\"\n",
    "    class PercentAboveLow(CustomFactor):\n",
    "        \"\"\"Percentage of current close above low \n",
    "        in lookback window of window_length days\n",
    "        \"\"\"\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            out[:] = close[-1] / np.min(close, axis=0) - 1\n",
    "\n",
    "    class PercentBelowHigh(CustomFactor):\n",
    "        \"\"\"Percentage of current close below high \n",
    "        in lookback window of window_length days\n",
    "        \"\"\"\n",
    "        \n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "            \n",
    "        def compute(self, today, assets, out, close):\n",
    "            out[:] = close[-1] / np.max(close, axis=0) - 1\n",
    "\n",
    "    @staticmethod\n",
    "    def make_dx(timeperiod=14):\n",
    "        class DX(CustomFactor):\n",
    "            \"\"\"Directional Movement Index\"\"\"\n",
    "            inputs = [USEquityPricing.high, \n",
    "                      USEquityPricing.low, \n",
    "                      USEquityPricing.close]\n",
    "            window_length = timeperiod + 1\n",
    "            \n",
    "            def compute(self, today, assets, out, high, low, close):\n",
    "                out[:] = [talib.DX(high[:, i], \n",
    "                                   low[:, i], \n",
    "                                   close[:, i], \n",
    "                                   timeperiod=timeperiod)[-1] \n",
    "                          for i in range(len(assets))]\n",
    "        return DX  \n",
    "\n",
    "    @staticmethod\n",
    "    def make_mfi(timeperiod=14):\n",
    "        class MFI(CustomFactor):\n",
    "            \"\"\"Money Flow Index\"\"\"\n",
    "            inputs = [USEquityPricing.high, \n",
    "                      USEquityPricing.low, \n",
    "                      USEquityPricing.close,\n",
    "                      USEquityPricing.volume]\n",
    "            window_length = timeperiod + 1\n",
    "            \n",
    "            def compute(self, today, assets, out, high, low, close, vol):\n",
    "                out[:] = [talib.MFI(high[:, i], \n",
    "                                    low[:, i], \n",
    "                                    close[:, i],\n",
    "                                    vol[:, i],\n",
    "                                    timeperiod=timeperiod)[-1] \n",
    "                          for i in range(len(assets))]\n",
    "        return MFI           \n",
    "\n",
    "    @staticmethod\n",
    "    def make_oscillator(fastperiod=12, slowperiod=26, matype=0):\n",
    "        class PPO(CustomFactor):\n",
    "            \"\"\"12/26-Day Percent Price Oscillator\"\"\"\n",
    "            inputs = [USEquityPricing.close]\n",
    "            window_length = slowperiod\n",
    "\n",
    "            def compute(self, today, assets, out, close_prices):\n",
    "                out[:] = [talib.PPO(close,\n",
    "                                    fastperiod=fastperiod,\n",
    "                                    slowperiod=slowperiod, \n",
    "                                    matype=matype)[-1]\n",
    "                         for close in close_prices.T]\n",
    "        return PPO\n",
    "\n",
    "    @staticmethod\n",
    "    def make_stochastic_oscillator(fastk_period=5, slowk_period=3, slowd_period=3, \n",
    "                                   slowk_matype=0, slowd_matype=0):                \n",
    "        class StochasticOscillator(CustomFactor):\n",
    "            \"\"\"20-day Stochastic Oscillator \"\"\"\n",
    "            inputs = [USEquityPricing.high, \n",
    "                      USEquityPricing.low, \n",
    "                      USEquityPricing.close]\n",
    "            outputs = ['slowk', 'slowd']\n",
    "            window_length = fastk_period * 2\n",
    "            \n",
    "            def compute(self, today, assets, out, high, low, close):\n",
    "                slowk, slowd = [talib.STOCH(high[:, i],\n",
    "                                            low[:, i],\n",
    "                                            close[:, i], \n",
    "                                            fastk_period=fastk_period,\n",
    "                                            slowk_period=slowk_period, \n",
    "                                            slowk_matype=slowk_matype, \n",
    "                                            slowd_period=slowd_period, \n",
    "                                            slowd_matype=slowd_matype)[-1] \n",
    "                                for i in range(len(assets))]\n",
    "\n",
    "                out.slowk[:], out.slowd[:] = slowk[-1], slowd[-1]\n",
    "        return StochasticOscillator\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_trendline(timeperiod=252):                \n",
    "        class Trendline(CustomFactor):\n",
    "            inputs = [USEquityPricing.close]\n",
    "            \"\"\"52-Week Trendline\"\"\"\n",
    "            window_length = timeperiod\n",
    "\n",
    "            def compute(self, today, assets, out, close_prices):\n",
    "                out[:] = [talib.LINEARREG_SLOPE(close, \n",
    "                                   timeperiod=timeperiod)[-1] \n",
    "                          for close in close_prices.T]\n",
    "        return Trendline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTUM_FACTORS = {\n",
    "    'Percent Above Low'            : MomentumFactors.PercentAboveLow,\n",
    "    'Percent Below High'           : MomentumFactors.PercentBelowHigh,\n",
    "    'Price Oscillator'             : MomentumFactors.make_oscillator(),\n",
    "    'Money Flow Index'             : MomentumFactors.make_mfi(),\n",
    "    'Directional Movement Index'   : MomentumFactors.make_dx(),\n",
    "    'Trendline'                    : MomentumFactors.make_trendline()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_result, t = factor_pipeline(MOMENTUM_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "momentum_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficiencyFactors:\n",
    "\n",
    "    @staticmethod\n",
    "    def CapexToAssets(mask):\n",
    "        \"\"\"Capital Expenditure divided by Total Assets\"\"\"\n",
    "        capex = AnnualizedData(inputs = [Fundamentals.capital_expenditure_asof_date,\n",
    "                                         Fundamentals.capital_expenditure],\n",
    "                                     mask=mask)   \n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return - capex / assets\n",
    "\n",
    "    @staticmethod\n",
    "    def CapexToSales(mask):\n",
    "        \"\"\"Capital Expenditure divided by Total Revenue\"\"\"\n",
    "        capex = AnnualizedData(inputs = [Fundamentals.capital_expenditure_asof_date,\n",
    "                                         Fundamentals.capital_expenditure],\n",
    "                                     mask=mask)   \n",
    "        revenue = AnnualizedData(inputs = [Fundamentals.total_revenue_asof_date,\n",
    "                                         Fundamentals.total_revenue],\n",
    "                                     mask=mask)         \n",
    "        return - capex / revenue\n",
    "  \n",
    "    @staticmethod\n",
    "    def CapexToFCF(mask):\n",
    "        \"\"\"Capital Expenditure divided by Free Cash Flows\"\"\"\n",
    "        capex = AnnualizedData(inputs = [Fundamentals.capital_expenditure_asof_date,\n",
    "                                         Fundamentals.capital_expenditure],\n",
    "                                     mask=mask)   \n",
    "        free_cash_flow = AnnualizedData(inputs = [Fundamentals.free_cash_flow_asof_date,\n",
    "                                         Fundamentals.free_cash_flow],\n",
    "                                     mask=mask)         \n",
    "        return - capex / free_cash_flow\n",
    "\n",
    "    @staticmethod\n",
    "    def EBITToAssets(mask):\n",
    "        \"\"\"Earnings Before Interest and Taxes (EBIT) divided by Total Assets\"\"\"\n",
    "        ebit = AnnualizedData(inputs = [Fundamentals.ebit_asof_date,\n",
    "                                         Fundamentals.ebit],\n",
    "                                     mask=mask)   \n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return ebit / assets\n",
    "    \n",
    "    @staticmethod\n",
    "    def CFOToAssets(mask):\n",
    "        \"\"\"Operating Cash Flows divided by Total Assets\"\"\"\n",
    "        cfo = AnnualizedData(inputs = [Fundamentals.operating_cash_flow_asof_date,\n",
    "                                         Fundamentals.operating_cash_flow],\n",
    "                                     mask=mask)   \n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return cfo / assets \n",
    "    \n",
    "    @staticmethod\n",
    "    def RetainedEarningsToAssets(mask):\n",
    "        \"\"\"Retained Earnings divided by Total Assets\"\"\"\n",
    "        retained_earnings = AnnualizedData(inputs = [Fundamentals.retained_earnings_asof_date,\n",
    "                                         Fundamentals.retained_earnings],\n",
    "                                     mask=mask)   \n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return retained_earnings / assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFFICIENCY_FACTORS = {\n",
    "    'CFO To Assets' :EfficiencyFactors.CFOToAssets,\n",
    "    'Capex To Assets' :EfficiencyFactors.CapexToAssets,\n",
    "    'Capex To FCF' :EfficiencyFactors.CapexToFCF,\n",
    "    'Capex To Sales' :EfficiencyFactors.CapexToSales,\n",
    "    'EBIT To Assets' :EfficiencyFactors.EBITToAssets,\n",
    "    'Retained Earnings To Assets' :EfficiencyFactors.RetainedEarningsToAssets\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_result, t = factor_pipeline(EFFICIENCY_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "efficiency_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskFactors:\n",
    "\n",
    "    @staticmethod\n",
    "    def LogMarketCap(mask):\n",
    "        \"\"\"Log of Market Capitalization log(Close Price * Shares Outstanding)\"\"\"\n",
    "        return np.log(MarketCap(mask=mask))\n",
    " \n",
    "    class DownsideRisk(CustomFactor):\n",
    "        \"\"\"Mean returns divided by std of 1yr daily losses (Sortino Ratio)\"\"\"\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            ret = pd.DataFrame(close).pct_change()\n",
    "            out[:] = ret.mean().div(ret.where(ret<0).std())\n",
    "\n",
    "    @staticmethod\n",
    "    def MarketBeta(**kwargs):\n",
    "        \"\"\"Slope of 1-yr regression of price returns against index returns\"\"\"\n",
    "        return SimpleBeta(target=symbols('SPY'), regression_length=252) \n",
    "\n",
    "    class DownsideBeta(CustomFactor):\n",
    "        \"\"\"Slope of 1yr regression of returns on negative index returns\"\"\"\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            t = len(close)\n",
    "            assets = pd.DataFrame(close).pct_change()\n",
    "            \n",
    "            start_date = (today - pd.DateOffset(years=1)).strftime('%Y-%m-%d')\n",
    "            spy = get_pricing('SPY', \n",
    "                              start_date=start_date, \n",
    "                              end_date=today.strftime('%Y-%m-%d')).reset_index(drop=True)\n",
    "            spy_neg_ret = (spy\n",
    "                           .close_price\n",
    "                           .iloc[-t:]\n",
    "                           .pct_change()\n",
    "                           .pipe(lambda x: x.where(x<0)))\n",
    "    \n",
    "            out[:] = assets.apply(lambda x: x.cov(spy_neg_ret)).div(spy_neg_ret.var())         \n",
    "\n",
    "    class Vol3M(CustomFactor):\n",
    "        \"\"\"3-month Volatility: Standard deviation of returns over 3 months\"\"\"\n",
    "\n",
    "        inputs = [USEquityPricing.close]\n",
    "        window_length = 63\n",
    "\n",
    "        def compute(self, today, assets, out, close):\n",
    "            out[:] = np.log1p(pd.DataFrame(close).pct_change()).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RISK_FACTORS = {\n",
    "    'Log Market Cap' : RiskFactors.LogMarketCap,\n",
    "    'Downside Risk'  : RiskFactors.DownsideRisk,\n",
    "    'Index Beta'     : RiskFactors.MarketBeta,\n",
    "#     'Downside Beta'  : RiskFactors.DownsideBeta,    \n",
    "    'Volatility 3M'  : RiskFactors.Vol3M,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_result, t = factor_pipeline(RISK_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "risk_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def growth_pipeline():\n",
    "    revenue = AnnualizedData(inputs = [Fundamentals.total_revenue_asof_date,\n",
    "                                       Fundamentals.total_revenue],\n",
    "                             mask=UNIVERSE)\n",
    "    eps = AnnualizedData(inputs = [Fundamentals.diluted_eps_earnings_reports_asof_date,\n",
    "                                       Fundamentals.diluted_eps_earnings_reports],\n",
    "                             mask=UNIVERSE)    \n",
    "\n",
    "    return Pipeline({'Sales': revenue,\n",
    "                     'EPS': eps,\n",
    "                     'Total Assets': Fundamentals.total_assets.latest,\n",
    "                     'Net Debt': Fundamentals.net_debt.latest},\n",
    "                    screen=UNIVERSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timer = time()\n",
    "growth_result = run_pipeline(growth_pipeline(), start_date=START, end_date=END)\n",
    "\n",
    "for col in growth_result.columns:\n",
    "    for month in [3, 12]:\n",
    "        new_col = col + ' Growth {}M'.format(month)\n",
    "        kwargs = {new_col: growth_result[col].pct_change(month*MONTH).groupby(level=1).rank()}        \n",
    "        growth_result = growth_result.assign(**kwargs)\n",
    "print('Pipeline run time {:.2f} secs'.format(time() - start_timer))\n",
    "growth_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityFactors:\n",
    "    \n",
    "    @staticmethod\n",
    "    def AssetTurnover(mask):\n",
    "        \"\"\"Sales divided by average of year beginning and year end assets\"\"\"\n",
    "\n",
    "        assets = AnnualAvg(inputs=[Fundamentals.total_assets],\n",
    "                           mask=mask)\n",
    "        sales = AnnualizedData([Fundamentals.total_revenue_asof_date,\n",
    "                                Fundamentals.total_revenue], mask=mask)\n",
    "        return sales / assets\n",
    "  \n",
    "    @staticmethod\n",
    "    def CurrentRatio(mask):\n",
    "        \"\"\"Total current assets divided by total current liabilities\"\"\"\n",
    "\n",
    "        assets = Fundamentals.current_assets.latest\n",
    "        liabilities = Fundamentals.current_liabilities.latest\n",
    "        return assets / liabilities\n",
    "    \n",
    "    @staticmethod\n",
    "    def AssetToEquityRatio(mask):\n",
    "        \"\"\"Total current assets divided by common equity\"\"\"\n",
    "\n",
    "        assets = Fundamentals.current_assets.latest\n",
    "        equity = Fundamentals.common_stock.latest\n",
    "        return assets / equity    \n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def InterestCoverage(mask):\n",
    "        \"\"\"EBIT divided by interest expense\"\"\"\n",
    "\n",
    "        ebit = AnnualizedData(inputs = [Fundamentals.ebit_asof_date,\n",
    "                                        Fundamentals.ebit], mask=mask)  \n",
    "        \n",
    "        interest_expense = AnnualizedData(inputs = [Fundamentals.interest_expense_asof_date,\n",
    "                                        Fundamentals.interest_expense], mask=mask)\n",
    "        return ebit / interest_expense\n",
    "\n",
    "    @staticmethod\n",
    "    def DebtToAssetRatio(mask):\n",
    "        \"\"\"Total Debts divided by Total Assets\"\"\"\n",
    "\n",
    "        debt = Fundamentals.total_debt.latest\n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return debt / assets\n",
    "    \n",
    "    @staticmethod\n",
    "    def DebtToEquityRatio(mask):\n",
    "        \"\"\"Total Debts divided by Common Stock Equity\"\"\"\n",
    "\n",
    "        debt = Fundamentals.total_debt.latest\n",
    "        equity = Fundamentals.common_stock.latest\n",
    "        return debt / equity    \n",
    "\n",
    "    @staticmethod\n",
    "    def WorkingCapitalToAssets(mask):\n",
    "        \"\"\"Current Assets less Current liabilities (Working Capital) divided by Assets\"\"\"\n",
    "\n",
    "        working_capital = Fundamentals.working_capital.latest\n",
    "        assets = Fundamentals.total_assets.latest\n",
    "        return working_capital / assets\n",
    " \n",
    "    @staticmethod\n",
    "    def WorkingCapitalToSales(mask):\n",
    "        \"\"\"Current Assets less Current liabilities (Working Capital), divided by Sales\"\"\"\n",
    "\n",
    "        working_capital = Fundamentals.working_capital.latest\n",
    "        sales = AnnualizedData([Fundamentals.total_revenue_asof_date,\n",
    "                                Fundamentals.total_revenue], mask=mask)        \n",
    "        return working_capital / sales          \n",
    "       \n",
    "        \n",
    "    class MertonsDD(CustomFactor):\n",
    "        \"\"\"Merton's Distance to Default \"\"\"\n",
    "        \n",
    "        inputs = [Fundamentals.total_assets,\n",
    "                  Fundamentals.total_liabilities, \n",
    "                  libor.value, \n",
    "                  USEquityPricing.close]\n",
    "        window_length = 252\n",
    "\n",
    "        def compute(self, today, assets, out, tot_assets, tot_liabilities, r, close):\n",
    "            mertons = []\n",
    "\n",
    "            for col_assets, col_liabilities, col_r, col_close in zip(tot_assets.T, tot_liabilities.T,\n",
    "                                                                     r.T, close.T):\n",
    "                vol_1y = np.nanstd(col_close)\n",
    "                numerator = np.log(\n",
    "                        col_assets[-1] / col_liabilities[-1]) + ((252 * col_r[-1]) - ((vol_1y ** 2) / 2))\n",
    "                mertons.append(numerator / vol_1y)\n",
    "\n",
    "            out[:] = mertons            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "QUALITY_FACTORS = {\n",
    "    'AssetToEquityRatio'    : QualityFactors.AssetToEquityRatio,\n",
    "    'AssetTurnover'         : QualityFactors.AssetTurnover,\n",
    "    'CurrentRatio'          : QualityFactors.CurrentRatio,\n",
    "    'DebtToAssetRatio'      : QualityFactors.DebtToAssetRatio,\n",
    "    'DebtToEquityRatio'     : QualityFactors.DebtToEquityRatio,\n",
    "    'InterestCoverage'      : QualityFactors.InterestCoverage,\n",
    "    'MertonsDD'             : QualityFactors.MertonsDD,\n",
    "    'WorkingCapitalToAssets': QualityFactors.WorkingCapitalToAssets,\n",
    "    'WorkingCapitalToSales' : QualityFactors.WorkingCapitalToSales,\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_result, t = factor_pipeline(QUALITY_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "quality_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PayoutFactors:\n",
    "\n",
    "    @staticmethod\n",
    "    def DividendPayoutRatio(mask):\n",
    "        \"\"\"Dividends Per Share divided by Earnings Per Share\"\"\"\n",
    "\n",
    "        dps = AnnualizedData(inputs = [Fundamentals.dividend_per_share_earnings_reports_asof_date,\n",
    "                                        Fundamentals.dividend_per_share_earnings_reports], mask=mask)  \n",
    "        \n",
    "        eps = AnnualizedData(inputs = [Fundamentals.basic_eps_earnings_reports_asof_date,\n",
    "                                        Fundamentals.basic_eps_earnings_reports], mask=mask)\n",
    "        return dps / eps\n",
    "    \n",
    "    @staticmethod\n",
    "    def DividendGrowth(**kwargs):\n",
    "        \"\"\"Annualized percentage DPS change\"\"\"        \n",
    "        return Fundamentals.dps_growth.latest    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAYOUT_FACTORS = {\n",
    "    'Dividend Payout Ratio': PayoutFactors.DividendPayoutRatio,\n",
    "    'Dividend Growth': PayoutFactors.DividendGrowth\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payout_result, t = factor_pipeline(PAYOUT_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "payout_result.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfitabilityFactors:\n",
    "    \n",
    "    @staticmethod\n",
    "    def GrossProfitMargin(mask):\n",
    "        \"\"\"Gross Profit divided by Net Sales\"\"\"\n",
    "\n",
    "        gross_profit = AnnualizedData([Fundamentals.gross_profit_asof_date,\n",
    "                              Fundamentals.gross_profit], mask=mask)  \n",
    "        sales = AnnualizedData([Fundamentals.total_revenue_asof_date,\n",
    "                                Fundamentals.total_revenue], mask=mask)\n",
    "        return gross_profit / sales   \n",
    "    \n",
    "    @staticmethod\n",
    "    def NetIncomeMargin(mask):\n",
    "        \"\"\"Net income divided by Net Sales\"\"\"\n",
    "\n",
    "        net_income = AnnualizedData([Fundamentals.net_income_income_statement_asof_date,\n",
    "                              Fundamentals.net_income_income_statement], mask=mask)  \n",
    "        sales = AnnualizedData([Fundamentals.total_revenue_asof_date,\n",
    "                                Fundamentals.total_revenue], mask=mask)\n",
    "        return net_income / sales   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFITABIILTY_FACTORS = {\n",
    "    'Gross Profit Margin': ProfitabilityFactors.GrossProfitMargin,\n",
    "    'Net Income Margin': ProfitabilityFactors.NetIncomeMargin,\n",
    "    'Return on Equity': Fundamentals.roe.latest,\n",
    "    'Return on Assets': Fundamentals.roa.latest,\n",
    "    'Return on Invested Capital': Fundamentals.roic.latest\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitability_result, t = factor_pipeline(PAYOUT_FACTORS)\n",
    "print('Pipeline run time {:.2f} secs'.format(t))\n",
    "payout_result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profitability_pipeline().show_graph(format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead = [1, 5, 10, 20]\n",
    "returns = run_pipeline(Pipeline({'Returns{}D'.format(i): Returns(inputs=[USEquityPricing.close], \n",
    "                                          window_length=i+1, mask=UNIVERSE) for i in lookahead},\n",
    "                                screen=UNIVERSE),\n",
    "                       start_date=START, \n",
    "                       end_date=END)\n",
    "return_cols = ['Returns{}D'.format(i) for i in lookahead]\n",
    "returns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([returns,\n",
    "                 value_result,\n",
    "                 momentum_result,\n",
    "                 quality_result,\n",
    "                 payout_result,\n",
    "                 growth_result,\n",
    "                 efficiency_result,\n",
    "                 risk_result], axis=1).sortlevel()\n",
    "data.index.names = ['date', 'asset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stock'] = data.index.get_level_values('asset').map(lambda x: x.asset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns and rows with less than 80% of data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before, cols_before = data.shape\n",
    "data = (data\n",
    "        .dropna(axis=1, thresh=int(len(data)*.8))\n",
    "        .dropna(thresh=int(len(data.columns) * .8)))\n",
    "data = data.fillna(data.median())\n",
    "rows_after, cols_after = data.shape\n",
    "print('{:,d} rows and {:,d} columns dropped'.format(rows_before-rows_after, cols_before-cols_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_index(1).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.clustermap(data.drop(['stock'] + return_cols, axis=1).corr())\n",
    "plt.gcf().set_size_inches((14,14));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(data.drop(return_cols, axis=1))\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifted Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = data.loc[:, return_cols]\n",
    "shifted_y = []\n",
    "for col in y.columns:\n",
    "    t = int(re.search(r'\\d+', col).group(0))\n",
    "    shifted_y.append(y.groupby(level='asset')['Returns{}D'.format(t)].shift(-t).to_frame(col))\n",
    "y = pd.concat(shifted_y, axis=1)\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(y[return_cols])\n",
    "ax.set_title('Return Distriubtions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns10D'\n",
    "outliers = .01\n",
    "model_data = pd.concat([y[[target]], X], axis=1).dropna().reset_index('asset', drop=True)\n",
    "model_data = model_data[model_data[target].between(*model_data[target].quantile([outliers, 1-outliers]).values)] \n",
    "\n",
    "model_data[target] = np.log1p(model_data[target])\n",
    "features = model_data.drop(target, axis=1).columns\n",
    "dates = model_data.index.unique()\n",
    "\n",
    "print(model_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data[target].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_split(d, nfolds=5, min_train=21):\n",
    "    \"\"\"Generate train/test dates for nfolds \n",
    "    with at least min_train train obs\n",
    "    \"\"\"\n",
    "    train_dates = d[:min_train].tolist()\n",
    "    n = int(len(dates)/(nfolds + 1)) + 1\n",
    "    test_folds = [d[i:i + n] for i in range(min_train, len(d), n)]\n",
    "    for test_dates in test_folds:\n",
    "        if len(train_dates) > min_train:\n",
    "            yield train_dates, test_dates\n",
    "        train_dates.extend(test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns10D'\n",
    "label = (y[target] > 0).astype(int).to_frame(target)\n",
    "model_data = pd.concat([label, X], axis=1).dropna().reset_index('asset', drop=True)\n",
    "\n",
    "features = model_data.drop(target, axis=1).columns\n",
    "dates = model_data.index.unique()\n",
    "\n",
    "print(model_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new categorical outcome variable, we can now train a logistic regression using the default L2 regularization. For logistic regression, the regularization is formulated inversely to linear regression: higher values for λ imply less regularization and vice versa. We evaluate 11 parameter values using cross validation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 250\n",
    "Cs = np.logspace(-5, 5, 11)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "logistic_results, logistic_coeffs = pd.DataFrame(), pd.DataFrame()\n",
    "for C in Cs:\n",
    "    print(C)\n",
    "    coeffs = []\n",
    "    log_reg = LogisticRegression(C=C)\n",
    "    for i, (train_dates, test_dates) in enumerate(time_series_split(dates, nfolds=nfolds)):\n",
    "\n",
    "        X_train = model_data.loc[idx[train_dates], features]\n",
    "        y_train = model_data.loc[idx[train_dates], target]\n",
    "        log_reg.fit(X=scaler.fit_transform(X_train), y=y_train)\n",
    "\n",
    "        X_test = model_data.loc[idx[test_dates], features]\n",
    "        y_test = model_data.loc[idx[test_dates], target]\n",
    "        y_pred = log_reg.predict_proba(scaler.transform(X_test))[:, 1]\n",
    "        \n",
    "        coeffs.append(log_reg.coef_.squeeze())\n",
    "        logistic_results = (logistic_results\n",
    "                            .append(y_test\n",
    "                                    .to_frame('actuals')\n",
    "                                    .assign(predicted=y_pred, C=C)))\n",
    "    logistic_coeffs[C] = np.mean(coeffs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results using AUC Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the roc_auc_score discussed in the previous chapter to compare the predictive accuracy across the various regularization parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_by_C = logistic_results.groupby('C').apply(lambda x: roc_auc_score(y_true=x.actuals.astype(int), \n",
    "                                                         y_score=x.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_by_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again plot the AUC result for the range of hyperparameter values alongside the coefficient path that shows the improvements in predictive accuracy as the coefficients are a bit shrunk at the optimal regularization value 102:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_auc = auc.iloc[-1]\n",
    "best_auc = auc.max()\n",
    "best_C = auc.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, sharex=True)\n",
    "\n",
    "auc_by_C.sort_index(ascending=False).plot(logx=True, title='Area under the Curve (AUC)', ax=axes[0])\n",
    "axes[0].axhline(y=base_auc, c='black')\n",
    "axes[0].axvline(x=best_C, c='darkgrey', ls='--')\n",
    "axes[0].set_xlabel('Regularization')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "\n",
    "logistic_coeffs.T.sort_index(ascending=False).plot(legend=False, logx=True, title='Logistic Ridge Path', ax=axes[1])\n",
    "axes[1].set_xlabel('Regularization')\n",
    "axes[1].set_ylabel('Coefficients')\n",
    "axes[1].axvline(x=best_C, c='darkgrey', ls='--')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Returns10D'\n",
    "label = (y[target] > 0).astype(int).to_frame(target)\n",
    "model_data = pd.concat([label, X], axis=1).dropna().reset_index('asset', drop=True)\n",
    "\n",
    "features = model_data.drop(target, axis=1).columns\n",
    "dates = model_data.index.unique()\n",
    "\n",
    "print(model_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
